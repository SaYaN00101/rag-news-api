# RAG News API üì∞üß†

[![Node.js](https://img.shields.io/badge/Node.js-18%2B-brightgreen)](https://nodejs.org/)
[![Express](https://img.shields.io/badge/Express-5.2-blue)](https://expressjs.com/)
[![License: ISC](https://img.shields.io/badge/license-ISC-blue.svg)](LICENSE)
[![Status: Assessment Submission](https://img.shields.io/badge/status-Assessment%20Submission-brightgreen)](#)
[![Docker](https://img.shields.io/badge/docker-compose-ready-blue)](#)

## Overview

RAG News API is a Node.js (Express) REST service that demonstrates a Retrieval-Augmented Generation (RAG) pipeline for answering user queries over a news corpus. It ingests news articles, generates embeddings, stores vectors in Qdrant, caches conversation state in Redis, and produces contextual answers via a pluggable LLM interface.

This project provides a production-oriented backend scaffold suitable for assessment or as a starter for a scalable news intelligence service. It emphasizes modular architecture, containerization, and clear testing steps for reviewers.

## Assessment Coverage (Edwid Tech)

This project was built specifically to satisfy the Backend Developer Assessment requirements.

| Requirement | Status |
|-----------|--------|
| RAG ingestion (~50 articles) | ‚úÖ Implemented via `/ingest` |
| Embeddings (Jina / OSS) | ‚úÖ Jina + fallback |
| Vector DB | ‚úÖ Qdrant |
| LLM (Gemini) | ‚úÖ Integrated + fallback |
| Redis session memory | ‚úÖ Implemented |
| SQL structured logs | ‚úÖ MySQL |
| REST APIs | ‚úÖ All required endpoints |
| Docker Compose | ‚úÖ Included |

> This section helps reviewers and HR quickly verify which assessment items are implemented.

---

## Features

### Core Functionality ‚öôÔ∏è
- ‚úÖ POST `/ingest` ‚Äî ingest ~50 news articles, store in MySQL, and upsert embeddings to Qdrant for retrieval.
- üîé Semantic Search ‚Äî top‚Äëk retrieval from Qdrant using Jina embeddings (fallback demo mode available).
- üí¨ POST `/chat` ‚Äî session-based chat that combines prior session context (Redis) and retrieved passages to produce answers.
- üìö Persistent Logs ‚Äî every interaction stored in MySQL for analytics and auditing.

### User Experience ‚ú®
- üßæ History endpoints: `GET /history/:sessionId` and `DELETE /history/:sessionId`.
- üîÅ Session caching in Redis for short-term memory / chat feel.
- üß∞ Docker Compose for repeatable local environment and demos.
- üõ°Ô∏è Graceful fallbacks when external services (Jina, Gemini, Qdrant) are unavailable.

### Content Sections
- Ingestion engine and scripts
- Embeddings pipeline and vector service
- Chat controller with RAG prompt composition
- Integration helpers (Gemini wrapper, Qdrant service)

---

## Tech Stack

### Frontend
- (None included) ‚Äî this repo focuses on backend services; examples use `curl`/Postman.

### Backend & Services
- Node.js + Express ‚Äî REST API and controllers.
- MySQL (`mysql2`) ‚Äî structured persistence for `articles` and `logs`.
- Redis ‚Äî session context caching (short-term memory).
- Qdrant ‚Äî vector database for semantic search (dockerized in compose).
- Jina AI ‚Äî embedding generation (uses `Jina` API; demo fallback available if key missing).
- Google GenAI (`@google/genai`) ‚Äî optional LLM integration (Gemini models); template fallback used when unavailable.

### Development Tools
- Docker & Docker Compose ‚Äî run full stack locally.
- dotenv ‚Äî environment variable management.
- axios ‚Äî HTTP client for external services.

---

## Installation

### Prerequisites
- Node.js v18+ and npm
- Docker & Docker Compose (recommended for full stack)
- MySQL or Docker with MySQL
- (Optional) `JINA_API_KEY` for embeddings and `GEMINI_API_KEY` for LLM access

### Step-by-step setup

1. Clone the repository

```bash
git clone <repo-url>
cd rag-news-api
```

2. Copy environment file and set variables

```bash
cp .env.example .env
# Edit .env and set MYSQL credentials, JINA_API_KEY, GEMINI_API_KEY etc.
```

3. Install dependencies

```bash
npm ci
```

> Note: If you later run `node app.js` manually and see an error like `Cannot find module 'swagger-ui-express'`, run `npm ci` (or `npm install`) to ensure all dependencies are installed. The server will still start without Swagger, but `/docs` will be unavailable until `swagger-ui-express` is installed. When running via Docker Compose with `docker compose up --build`, dependencies are installed in the image and `/docs` will be available.

4. Initialize DB tables

```bash
npm run init-db
```

5. Start the application (local)

```bash
node app.js
# Server runs on http://localhost:3000
```

6. Or start full stack via Docker Compose

```bash
docker compose up --build
```

---

## Usage

### 1) Ingest sample articles

```bash
curl -X POST http://localhost:3000/ingest -H "Content-Type: application/json"
```
- Verifies MySQL insert and upserts vectors to Qdrant.

### 2) Chat (RAG)

```bash
curl -X POST http://localhost:3000/chat \
  -H "Content-Type: application/json" \
  -d '{"sessionId":"demo1","query":"Tell me about recent headlines"}'
```
- Response includes `response` and `sources` (titles of retrieved passages).

### 3) Session History

```bash
curl http://localhost:3000/history/demo1
curl -X DELETE http://localhost:3000/history/demo1
```

---

## Project Structure

```
rag-news-api/
‚îú‚îÄ app.js                   # Express app + route wiring
‚îú‚îÄ package.json
‚îú‚îÄ Dockerfile
‚îú‚îÄ docker-compose.yml
‚îú‚îÄ scripts/
‚îÇ  ‚îî‚îÄ init-db.js            # Initializes MySQL schema (articles, logs)
‚îú‚îÄ src/
‚îÇ  ‚îú‚îÄ controllers/
‚îÇ  ‚îÇ  ‚îú‚îÄ ingestController.js
‚îÇ  ‚îÇ  ‚îî‚îÄ chatController.js
‚îÇ  ‚îú‚îÄ services/
‚îÇ  ‚îÇ  ‚îú‚îÄ embeddingService.js
‚îÇ  ‚îÇ  ‚îú‚îÄ qdrantService.js
‚îÇ  ‚îÇ  ‚îú‚îÄ vectorService.js
‚îÇ  ‚îÇ  ‚îî‚îÄ geminiService.js
‚îÇ  ‚îú‚îÄ routes/
‚îÇ  ‚îÇ  ‚îú‚îÄ ingestRoutes.js
‚îÇ  ‚îÇ  ‚îú‚îÄ chatRoutes.js
‚îÇ  ‚îÇ  ‚îî‚îÄ historyRoutes.js
‚îÇ  ‚îú‚îÄ db.js                 # MySQL connection pool
‚îÇ  ‚îî‚îÄ redisClient.js
‚îî‚îÄ README.md
```

### File descriptions

| File | Description |
|------|-------------|
| `app.js` | Express app and route registration |
| `scripts/init-db.js` | Creates `articles` and `logs` tables |
| `src/controllers/ingestController.js` | Ingest articles, create embeddings, upsert to Qdrant |
| `src/controllers/chatController.js` | Chat endpoint (RAG flow + session logging) |
| `src/services/embeddingService.js` | Jina embedding wrapper (+ demo fallback) |
| `src/services/vectorService.js` | Qdrant collection management + search/upsert |
| `src/services/geminiService.js` | LLM wrapper (Gemini via `@google/genai`) and template fallback |
| `src/redisClient.js` | Configured Redis client with safe wrappers |

---

## Screenshots

> Placeholder screenshot: Ingestion success message (shows HTTP response and MySQL table count)

> Placeholder screenshot: Chat response with retrieved sources

> Placeholder screenshot: Docker Compose services running (MySQL, Redis, Qdrant, API)

---

## Integration / External Services Setup

### Jina AI (Embeddings)
1. Create account at Jina.ai and get an API key.
2. Set `JINA_API_KEY` in `.env`.
3. The app will call Jina for embeddings during `/ingest`. If the key is not present, a deterministic demo fallback zero-vector is used.

### Qdrant (Vector DB)
1. Docker Compose includes Qdrant; it listens on `http://localhost:6333` by default.
2. Configure `QDRANT_URL` in `.env` to point to your Qdrant instance.

### Google Gemini (GenAI)
1. Obtain `GEMINI_API_KEY` from Google AI Studio and set it in `.env`.
2. Set `GEMINI_MODEL` in `.env` to pin a model (e.g., `gemini-2.5-flash`).

> **Note:** Gemini model availability depends on your API key, account, and region. The default model is configurable via `GEMINI_MODEL`. If the specified model is unavailable, the service automatically falls back to a deterministic template response to keep the API functional.

3. The code uses the `@google/genai` client; if the client is not installed or the specified model does not exist on your account, a template-based fallback ensures `/chat` still returns a helpful response for demos.

---

## Roadmap

**Short-term (1-2 months)**
- Implement streaming responses (SSE) for `/chat`.
- Postman collection available at `dev-tools/postman_collection.json`. Import into Postman or Thunder Client and set `baseUrl` to `http://localhost:3000`.
- Swagger UI available at `http://localhost:3000/docs` when server is running.
- Add more robust validation & standardized error middleware.

**Mid-term (3-6 months)**
- Add ingestion queue (BullMQ) for scalability and background processing.
- Add rate-limiting and authentication (API keys / JWT).
- Add unit and integration tests and CI pipelines.

**Long-term (6+ months)**
- Production deployment templates (Kubernetes, observability, autoscaling).
- Multi-tenant ingestion and per-tenant vector namespaces.

---

## Known Limitations

- Streaming responses are not enabled by default (planned via SSE).
- Ingestion is synchronous in demo mode; background queues are planned.
- Authentication and rate limiting are not enabled in this assessment version.

---

## Contributing

1. Fork the repo and create a feature branch.
2. Open a pull request with a clear description and tests.
3. We welcome improvements, bug fixes, and documentation enhancements.

Contribution ideas:
- Add Swagger UI and Postman export.
- Implement streaming and client-sent events for chat.
- Add authentication and role-based permissions.

---

## License

This project is licensed under the **ISC License** ‚Äî see `LICENSE` for details. You may use, modify, and distribute this code under the terms of the license.

---

## Acknowledgments

Thanks to the Jina, Qdrant, Google GenAI, Redis, and MySQL communities and libraries used in this project.

---

## Contact

- GitHub: [your-github-username](https://github.com/your-github-username)
- Email: hr@edwidtech.com (for submissions)
- LinkedIn: https://www.linkedin.com/in/your-profile

---

## Additional Tips

- Performance: batch embeddings during ingestion and upsert in chunks to reduce latency.
- Deployment: use `docker compose` for local testing and create a production Compose/K8s manifest for deployment.
- Customization: provide `GEMINI_MODEL` and `QDRANT_COLLECTION` env vars to configure behavior.
- Troubleshooting: check service logs (Qdrant, Redis, MySQL) and ensure env vars are set.
- Learning: read docs for Jina, Qdrant, and Google GenAI to tune prompts and embedding models.

---

**Last updated:** 2025-12-16

**Status:** WIP

**Created by:** Sayan Jagulia


